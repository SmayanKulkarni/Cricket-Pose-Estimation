{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a53de23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 17:32:04.605186: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-28 17:32:04.727976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753704124.773236    5143 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753704124.786436    5143 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753704124.893479    5143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753704124.893492    5143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753704124.893493    5143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753704124.893494    5143 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-28 17:32:04.904763: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51adf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/smayan/Desktop/Cricket Pose Estimation /Data'\n",
    "sequence_length = 30\n",
    "min_sequences_per_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f60e315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array(sorted([folder for folder in os.listdir(DATA_PATH) \n",
    "                          if os.path.isdir(os.path.join(DATA_PATH, folder))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae87404",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label: num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efbe66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fffd86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('training_data.npy')\n",
    "y = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c69be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "y_categorical = to_categorical(y, num_classes=len(actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37f28381",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_categorical, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b40965f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7376cdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smayan/Desktop/AI-ML-DS/AI-and-ML-Course/.conda/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1753700752.496484  563885 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1166 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Apply Conv1D across time dimension\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# LSTM after CNN\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)))\n",
    "model.add(LSTM(32, return_sequences=False, dropout=0.3, recurrent_dropout=0.2))\n",
    "\n",
    "# Dense layers\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(len(actions), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4afebf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = f'logs/cricket_model_{timestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c95c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfad29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, update_freq='epoch'),\n",
    "    EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=10, min_lr=1e-7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77d58b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753700757.749167  565052 cuda_dnn.cc:529] Loaded cuDNN version 91100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 0.0920 - loss: 2.6237 - val_accuracy: 0.1340 - val_loss: 2.4179 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.1223 - loss: 2.4330 - val_accuracy: 0.1495 - val_loss: 2.2056 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.1659 - loss: 2.2567 - val_accuracy: 0.2371 - val_loss: 2.0691 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.2021 - loss: 2.1420 - val_accuracy: 0.2655 - val_loss: 1.9914 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.2069 - loss: 2.0765 - val_accuracy: 0.3454 - val_loss: 1.8395 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.2526 - loss: 1.9575 - val_accuracy: 0.3943 - val_loss: 1.7568 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.3027 - loss: 1.8568 - val_accuracy: 0.3943 - val_loss: 1.6831 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.3329 - loss: 1.8208 - val_accuracy: 0.4304 - val_loss: 1.6352 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.3694 - loss: 1.6794 - val_accuracy: 0.4716 - val_loss: 1.5153 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.4172 - loss: 1.6305 - val_accuracy: 0.4845 - val_loss: 1.4509 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.4284 - loss: 1.5405 - val_accuracy: 0.5361 - val_loss: 1.3807 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.4863 - loss: 1.4444 - val_accuracy: 0.5335 - val_loss: 1.3383 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.4793 - loss: 1.4434 - val_accuracy: 0.5644 - val_loss: 1.3001 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.4551 - loss: 1.4910 - val_accuracy: 0.5902 - val_loss: 1.1822 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5281 - loss: 1.2768 - val_accuracy: 0.5593 - val_loss: 1.2771 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5134 - loss: 1.3636 - val_accuracy: 0.6263 - val_loss: 1.1268 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5298 - loss: 1.2815 - val_accuracy: 0.6495 - val_loss: 1.0765 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5609 - loss: 1.2050 - val_accuracy: 0.6263 - val_loss: 1.0936 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5145 - loss: 1.3335 - val_accuracy: 0.6546 - val_loss: 1.0343 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5782 - loss: 1.1414 - val_accuracy: 0.6340 - val_loss: 1.0255 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.5571 - loss: 1.1849 - val_accuracy: 0.6727 - val_loss: 0.9789 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6147 - loss: 1.1089 - val_accuracy: 0.6753 - val_loss: 0.9313 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6047 - loss: 1.0546 - val_accuracy: 0.7010 - val_loss: 0.9344 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6209 - loss: 1.0482 - val_accuracy: 0.6521 - val_loss: 0.9993 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.5758 - loss: 1.1389 - val_accuracy: 0.6907 - val_loss: 0.9088 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6692 - loss: 0.9555 - val_accuracy: 0.7191 - val_loss: 0.8565 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.6386 - loss: 1.0172 - val_accuracy: 0.7113 - val_loss: 0.8682 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.6784 - loss: 0.9151 - val_accuracy: 0.7500 - val_loss: 0.8193 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7093 - loss: 0.8768 - val_accuracy: 0.7345 - val_loss: 0.7702 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.6902 - loss: 0.8817 - val_accuracy: 0.7242 - val_loss: 0.7672 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7195 - loss: 0.8140 - val_accuracy: 0.7448 - val_loss: 0.7911 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7208 - loss: 0.7678 - val_accuracy: 0.7113 - val_loss: 0.7906 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7012 - loss: 0.8493 - val_accuracy: 0.7912 - val_loss: 0.6629 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7204 - loss: 0.8209 - val_accuracy: 0.7758 - val_loss: 0.6709 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7493 - loss: 0.7557 - val_accuracy: 0.7680 - val_loss: 0.6746 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7425 - loss: 0.7806 - val_accuracy: 0.7912 - val_loss: 0.6266 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7763 - loss: 0.7014 - val_accuracy: 0.7732 - val_loss: 0.6710 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.7573 - loss: 0.7210 - val_accuracy: 0.7861 - val_loss: 0.6627 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7693 - loss: 0.7175 - val_accuracy: 0.7809 - val_loss: 0.6243 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7745 - loss: 0.6777 - val_accuracy: 0.8015 - val_loss: 0.5852 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7782 - loss: 0.6526 - val_accuracy: 0.7964 - val_loss: 0.5878 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7975 - loss: 0.6422 - val_accuracy: 0.8170 - val_loss: 0.5415 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7697 - loss: 0.7021 - val_accuracy: 0.7861 - val_loss: 0.6730 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8079 - loss: 0.6414 - val_accuracy: 0.8067 - val_loss: 0.5978 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7965 - loss: 0.6020 - val_accuracy: 0.8376 - val_loss: 0.5212 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.7975 - loss: 0.6140 - val_accuracy: 0.8196 - val_loss: 0.5647 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8211 - loss: 0.5631 - val_accuracy: 0.8196 - val_loss: 0.5731 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8109 - loss: 0.5596 - val_accuracy: 0.8273 - val_loss: 0.5399 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8319 - loss: 0.4966 - val_accuracy: 0.8196 - val_loss: 0.5236 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8197 - loss: 0.5263 - val_accuracy: 0.8222 - val_loss: 0.5012 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03d41aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8222\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89c9a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('cricket_pose_mode_simple_even_noTime.h5')\n",
    "model.save('cricket_pose_mode_simple_even_noTime.keras')\n",
    "np.save('cricket_label_map.npy', label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d859ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "I0000 00:00:1753704398.087833    5143 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1753704398.137657   28085 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 570.172.08), renderer: NVIDIA GeForce RTX 4070 SUPER/PCIe/SSE2\n",
      "W0000 00:00:1753704398.168215   28065 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1753704398.188618   28062 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1753704398.190173   28062 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1753704398.190574   28070 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1753704398.190854   28074 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1753704398.194168   28065 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1753704398.199138   28062 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1753704398.204282   28083 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Load trained model and label map\n",
    "model = tf.keras.models.load_model('cricket_pose_mode_simple_even.h5')\n",
    "label_map = np.load('cricket_label_map.npy', allow_pickle=True).item()\n",
    "actions = list(label_map.keys())\n",
    "\n",
    "# Variables for prediction\n",
    "sequence = []\n",
    "sequence_length = 30\n",
    "threshold = 0.7\n",
    "\n",
    "# Start webcam\n",
    "cap = cv.VideoCapture('/home/smayan/Desktop/Cricket Pose Estimation /Model Training/test2.mp4')\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize for consistent input\n",
    "        frame = cv.resize(frame, (640, 480))\n",
    "\n",
    "        # Detection\n",
    "        image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = holistic.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "            )\n",
    "\n",
    "        # Extract keypoints\n",
    "        if results.pose_landmarks:\n",
    "            keypoints = np.array([[res.x, res.y, res.z, res.visibility]\n",
    "                                  for res in results.pose_landmarks.landmark]).flatten()\n",
    "        else:\n",
    "            keypoints = np.zeros(33*4)\n",
    "\n",
    "        # Append to sequence\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-sequence_length:]\n",
    "\n",
    "        if len(sequence) == sequence_length:\n",
    "            input_seq = np.expand_dims(np.array(sequence), axis=0)\n",
    "            input_seq = input_seq.reshape(1, sequence_length, -1, 1)\n",
    "\n",
    "            # Predict\n",
    "            res = model.predict(input_seq, verbose=0)[0]\n",
    "            predicted_action = actions[np.argmax(res)]\n",
    "            confidence = np.max(res)\n",
    "\n",
    "            # Show prediction\n",
    "            if confidence > threshold:\n",
    "                cv.putText(image, f'{predicted_action}: {confidence:.2f}',\n",
    "                           (10, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Show probabilities\n",
    "            for i, (action, prob) in enumerate(zip(actions, res)):\n",
    "                y_pos = 100 + i * 30\n",
    "                cv.rectangle(image, (10, y_pos), (int(prob * 300) + 10, y_pos + 25), (0, 255, 0), -1)\n",
    "                cv.putText(image, f'{action}: {prob:.2f}', (15, y_pos + 18),\n",
    "                           cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "        # Show output\n",
    "        cv.imshow('Cricket Pose Estimation', image)\n",
    "\n",
    "        # Quit\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4484c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
